import numpy as np
import matplotlib.pyplot as plt

def get_probabilities():
    probs = [
        np.random.normal(0, 5),
        np.random.normal(-0.5, 12),
        np.random.normal(2, 3.9),
        np.random.normal(-0.5, 7),
        np.random.normal(-1.2, 8),
        np.random.normal(-3, 7),
        np.random.normal(-10, 20),
        np.random.normal(-0.5, 1),
        np.random.normal(-1, 2),
        np.random.normal(1, 6),
        np.random.normal(0.7, 4),
        np.random.normal(-6, 11),
        np.random.normal(-7, 1),
        np.random.normal(-0.5, 2),
        np.random.normal(-6.5, 1),
        np.random.normal(-3, 6),
        np.random.normal(0, 8),
        np.random.normal(2, 3.9),
        np.random.normal(-9, 12),
        np.random.normal(-1, 6),
        np.random.normal(-4.5, 8)
    ]
    return probs

def epsilon_greedy_test(num_steps, num_choices, epsilon):
    estimated_rewards = np.zeros(num_choices)
    action_counts = np.zeros(num_choices)
    total_reward = 0
    average_rewards = np.zeros(num_steps)
    probs = get_probabilities()

    for step in range(num_steps):
        if np.random.rand() < epsilon:
            action = np.random.randint(num_choices)
        else:
            action = np.argmax(estimated_rewards)
        
        reward = probs[action]
        
        action_counts[action] += 1
        estimated_rewards[action] += (reward - estimated_rewards[action]) / action_counts[action]
        total_reward += reward
        
        average_rewards[step] = total_reward / (step + 1)
    
    return average_rewards

def thompson_sampling_test(num_steps, num_choices):
    success_counts = np.zeros(num_choices)
    failure_counts = np.zeros(num_choices)
    total_reward = 0
    average_rewards = np.zeros(num_steps)
    probs = get_probabilities()

    for step in range(num_steps):
        samples = np.random.beta(success_counts + 1, failure_counts + 1)
        action = np.argmax(samples)
        
        reward = probs[action]
        
        if reward > 0:
            success_counts[action] += reward
        else:
            failure_counts[action] -= reward
        
        total_reward += reward
        average_rewards[step] = total_reward / (step + 1)
    
    return average_rewards

def run_experiment(num_runs, num_steps, num_choices):
    epsilon_values = [0.01, 0.05, 0.1, 0.4]
    avg_rewards_epsilon = {epsilon: np.zeros(num_steps) for epsilon in epsilon_values}
    avg_rewards_thompson = np.zeros(num_steps)

    for _ in range(num_runs):
        for epsilon in epsilon_values:
            avg_rewards_epsilon[epsilon] += epsilon_greedy_test(num_steps, num_choices, epsilon)
        
        avg_rewards_thompson += thompson_sampling_test(num_steps, num_choices)

    # Average the results
    for epsilon in epsilon_values:
        avg_rewards_epsilon[epsilon] /= num_runs
    avg_rewards_thompson /= num_runs

    return avg_rewards_epsilon, avg_rewards_thompson

# Run the experiment
num_runs = 20
num_steps = 10000
num_choices = 21  # Matches the number of probabilities in get_probabilities()

avg_rewards_epsilon, avg_rewards_thompson = run_experiment(num_runs, num_steps, num_choices)

# Plot the results
plt.figure(figsize=(12, 8))
for epsilon, rewards in avg_rewards_epsilon.items():
    plt.plot(rewards, label=f'ε-greedy (ε = {epsilon})')
plt.plot(avg_rewards_thompson, label='Thompson Sampling', color='black', linewidth=2)

plt.title('Convergence Rates of ε-greedy vs. Thompson Sampling')
plt.xlabel('Steps')
plt.ylabel('Average Reward')
plt.legend()
plt.grid(True)
plt.show()